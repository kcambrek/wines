{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making sense of text through NLP and machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% of the data that resides in companies have been estimated to be unstructured i.e. data that is not organized in a way that allows easy analysis. We are surrounded by this kind of data and comes often in textual form such as emails, memo's, social media posts, articles and endless documents. Immediately regarding this data as useless for data analysis techniques such as machine learning models would be naive. You might be surprised how much we already can do.\n",
    "\n",
    "This article has a different setup than you might be used to from IThappens. Instead of only discussing concepts and how they impact business, this article will also offer code in Python to demonstrate how to bring it in practice. This article will not go in depth into the coding language used or technologies used, but I will provide you with usefull links if you want to learn more and invite you to play around with the code.\n",
    "\n",
    "The dataset used in this article is rather trivial, but depending on your lifestyle, the data might interest some of you to a great extend. This dataset contains 150,000 wine reviews gathered by a Kaggle users. Every entry contains the name, price, country of origin, textual review and points of the wine. The goal of the excercise in this article is trying to classify if a wine is a top wine (at least 9 out of 10 points) based on the textual review.\n",
    "\n",
    "Important is to note that there is no \"one\" true best model, or as they like to say in machine learning: there is no free lunch. Therefore, we have to work through trial and error untill we find something that give satisfactory results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import keras\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from sklearn.metrics import recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to load the data, look at some examples and prepare the data in order to train some models on it. Collecting, exploring and pre-processing your data could take up to 80% of a whole data science project. Luckily, the data is available in a csv file and little pre-processing is necessary.\n",
    "\n",
    "The data will be loaded in a pandas data frame, which allows easy exploration and visualisation of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winemag-data_first150k.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to explore our data is to simply look at. Below the first 5 entries and the first 5 whole reviews are presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1           1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4           4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.\n",
      "\n",
      "\n",
      "Ripe aromas of fig, blackberry and cassis are softened and sweetened by a slathering of oaky chocolate and vanilla. This is full, layered, intense and cushioned on the palate, with rich flavors of chocolaty black fruits and baking spices. A toasty, everlasting finish is heady but ideally balanced. Drink through 2023.\n",
      "\n",
      "\n",
      "Mac Watson honors the memory of a wine once made by his mother in this tremendously delicious, balanced and complex botrytised white. Dark gold in color, it layers toasted hazelnut, pear compote and orange peel flavors, reveling in the succulence of its 122 g/L of residual sugar.\n",
      "\n",
      "\n",
      "This spent 20 months in 30% new French oak, and incorporates fruit from Ponzi's Aurora, Abetina and Madrona vineyards, among others. Aromatic, dense and toasty, it deftly blends aromas and flavors of toast, cigar box, blackberry, black cherry, coffee and graphite. Tannins are polished to a fine sheen, and frame a finish loaded with dark chocolate and espresso. Drink now through 2032.\n",
      "\n",
      "\n",
      "This is the top wine from La Bégude, named after the highest point in the vineyard at 1200 feet. It has structure, density and considerable acidity that is still calming down. With 18 months in wood, the wine has developing an extra richness and concentration. Produced by the Tari family, formerly of Château Giscours in Margaux, it is a wine made for aging. Drink from 2020.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#example of a description\n",
    "for text in (df.description[0:5]):\n",
    "    print(text)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that not every description has the same length. This could be problematic for training a model on the descriptions, since a longer description can contain much more important terms that can indicate the quality of the wine compared to smaller descriptions. Plotting the length of the descriptions reveals a substantial amount of outliers. Therefore, the descriptions will be restricted to 1 or 2 sentences, which corresponds roughly to sentences with between 15 and 40 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of words')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_length = [len(text.split()) for text in df.description]\n",
    "plt.boxplot(text_length)\n",
    "plt.ylabel(\"Number of words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering out all the descriptions that do not meet our criteria\n",
    "df['description'] = df['description'].astype('str')\n",
    "\n",
    "filtered = df[df.description.str.split().apply(len) > 15]\n",
    "data = filtered[filtered.description.str.split().apply(len) < 45]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of words')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_length = [len(text.split()) for text in data.description]\n",
    "plt.boxplot(text_length)\n",
    "plt.ylabel(\"Number of words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how many of our original data we are left with, we simply compare the number of old entries with our filtered data. 66% of our data has been preserves, which still mean that we are left with a hefty data set of 100,000 wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.5162658185914"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#around 2/3 of the data is being kept\n",
    "len(data.description)/len(df.description)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we have to label our data in a fitting manner. Since we only deal with two classes, top wines and other wines, the task at hand is binary classification. Therefore, we can simple label the top wines with a 1 and the other wines with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    87065\n",
       "1    13328\n",
       "Name: categorical, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"categorical\"] = [1 if score > 90 else 0 for score in data.points]\n",
    "data[\"categorical\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the end of this section. Before we can train models on our data, we would like to define what would constitute to a good performance. It might be a good idea to look at the distribution of wine points in our data set. \n",
    "\n",
    "The plot below shows us clearly that most of our wines do not belong to the top wines (at least 9 out of 10 points). This means that our data is *unbalanced*, which might result in problems for training a model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'wine points distribution')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.points)\n",
    "plt.ylabel(\"count\")\n",
    "plt.xlabel(\"points\")\n",
    "plt.title(\"wine points distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our excercise has the goal to correctly classify all the top wines. We could easily label all of our wines as top wines and call it a day. While some of us do not really care about the quantity of wine, but if we want to try all the top wines, we do not want to try all the other wines to. Therefore, we should evaluate our models on two metrics: *accuracy* and *recall*.\n",
    "\n",
    "Accuracy is the percentage of how many wines we classified correctly from *all* the wines. \n",
    "Recall is the percentage of many wines we classfied correctly from the *top* wines. \n",
    "\n",
    "We would like to get our recall as high as possible and our accuracy at least higher than the case where we classify everything as a inferior wine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8672417399619495\n",
      "Train recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kees\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions = [0 for i in data.points]\n",
    "print(\"Accuracy: \" + str(accuracy_score(predictions, data.categorical)))\n",
    "print(\"Recall: \" + str(recall_score(predictions, data.categorical)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we should not evaluate on the data on which we trained. When you studhy for an exam, you study (or train) on different excercises than the excercises in the exam. If you would have been studying by using the excercises in the exam, the exam would not fairly evaluate your knowledge on the subject. Therefore, we split the data in a large training set and a smaller set for evaluating our models. The code below dives the data in 75% and 25% for the train and test set respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.description, data.categorical, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "This section might be the most complicated of this excersice. In order to let machine learning models work with the descriptions, the text needs to be converted to numerical representations such a vectors. For this problem, sentence embeddings are used in order to capture the semantics of the whole sentence(s).\n",
    "\n",
    "Simply put, embeddings give sentences that are similair in semantics similair vectors. As a result, similair sentences are mapped closed together in the feature space. This description clearly does not justify the miracelous and complex workings of sentence embedding models and the larger field of language understanding. This field has seen a tremendous amount of advancement in recent years and record after record is being broken every few months. If you would like to read more on this topic, I advice to start with ...\n",
    "\n",
    "The convert the text to vectors, a pre-trained Skip-Thought model has been used. The model has been trained on a large data set on which it learned to predict the previous and next sentence given the input sentence. The idea is that by learning surrounding sentences, the semantics of the input sentence can be learned. This model can be used to pre-process sentences for different NLP tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skip_thoughts import configuration\n",
    "from skip_thoughts import encoder_manager\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data for the encoder\n",
    "skt_data = [line.strip() for line in data.description]\n",
    "assert len(skt_data) == len(data.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading vocabulary from C:\\Users\\Kees\\Python\\Thesis_CSAI\\skipthought\\skip_thoughts_bi_2017_02_16\\vocab.txt\n",
      "INFO:tensorflow:Loaded vocabulary with 930914 words.\n",
      "INFO:tensorflow:Loading embedding matrix from C:\\Users\\Kees\\Python\\Thesis_CSAI\\skipthought\\skip_thoughts_bi_2017_02_16\\embeddings.npy\n",
      "INFO:tensorflow:Loaded embedding matrix with shape (930914, 620)\n",
      "INFO:tensorflow:Building model.\n",
      "WARNING:tensorflow:From C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\skip_thoughts\\skip_thoughts_model.py:71: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\skip_thoughts\\skip_thoughts_model.py:231: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\skip_thoughts\\skip_thoughts_model.py:246: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\skip_thoughts\\skip_thoughts_model.py:360: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "INFO:tensorflow:Loading model from checkpoint: C:\\Users\\Kees\\Python\\Thesis_CSAI\\skipthought\\skip_thoughts_bi_2017_02_16\\model.ckpt-500008\n",
      "WARNING:tensorflow:From C:\\Users\\Kees\\Anaconda\\envs\\Thesis\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Kees\\Python\\Thesis_CSAI\\skipthought\\skip_thoughts_bi_2017_02_16\\model.ckpt-500008\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-500008\n"
     ]
    }
   ],
   "source": [
    "bi_skt_encoder = encoder_manager.EncoderManager()\n",
    "bi_skt_encoder.load_model(configuration.model_config(bidirectional_encoder=True),\n",
    "                   vocabulary_file= r\"C:\\Users\\Kees\\Python\\Thesis_CSAI\\skipthought\\skip_thoughts_bi_2017_02_16\\vocab.txt\",\n",
    "                   embedding_matrix_file=r\"C:\\Users\\Kees\\Python\\Thesis_CSAI\\skipthought\\skip_thoughts_bi_2017_02_16\\embeddings.npy\",\n",
    "                   checkpoint_path=r\"C:\\Users\\Kees\\Python\\Thesis_CSAI\\skipthought\\skip_thoughts_bi_2017_02_16\\model.ckpt-500008\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the sentences to embeddings takes some time and we would not like to run the Skip-Thought model everytime we restart our computer. Therefore, we save them in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_skt_embedding = bi_skt_encoder.encode(skt_data)\n",
    "\n",
    "bi_skt_embedding_file = open('bi_skt_embedding_file', 'wb')\n",
    "\n",
    "pickle.dump(bi_skt_embedding, bi_skt_embedding_file)\n",
    "bi_skt_embedding_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three lines of code below allow us to load the embeddings from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('bi_skt_embedding_file', \"rb\")\n",
    "embeddings = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if all the embeddings are loaded, we can check the shape of the embeddings. Around 100,000 vectors with size 2400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100393, 2400)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_skt_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2400 might be too much for our task and will make our machine learning models a bit too complex. Sklearn offers us a neat trick: principle component analysis (PCA). Simply put, PCA allows us to reduce the dimensions (features) while trying to preserve the information stored in the initial dimensions. The exact working of the algorithm behind PCA can be a bit daunting, so I included a gif that might give you some intuition on how it works.\n",
    "\n",
    "![PCAUrl](https://miro.medium.com/max/770/1*UpFltkN-kT9aGqfLhOR9xg.gif \"PCA\")\n",
    "\n",
    "Source: https://medium.com/@raghavan99o/principal-component-analysis-pca-explained-and-implemented-eeab7cb73b72\n",
    "\n",
    "We need to fit the PCA on our data in order to let the PCA-model learn its distribution. Important is to note that we fit the PCA on our training data and not on our testing data. We do not want the test data to influence how the train data is pre-processed. It is always important to keep in mind what pre-processing techniques we can apply on our train and test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(embeddings, data.categorical, random_state  = 42)\n",
    "#Delete this??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1000)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model that we will train on our data is K-nearest neighbour. This is a fairly simple model that can work remarkably well on certain data sets. The model remembers the positions in the feature space of all the examples in the train set. When it is asked to classify a wine from the test data set, the model looks at the classes of *k* nearest wines in the feature space and through majority vote classifies the wine.\n",
    "\n",
    "This model has one major weakpoint: it cannot handle data with a lot of dimensions well. This weakness is also called the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). Therefore, we will apply PCA again, specifically for KNN. 20 dimensions seem to be reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pca = PCA(n_components = 20)\n",
    "\n",
    "X_train_knn = knn_pca.fit_transform(X_train)\n",
    "X_test_knn = knn_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the KNN classifier from Sklearn and fit our training examples on it in three lines of code. Yes, this easy it can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs = -1)\n",
    "knn.fit(X_train_knn, y_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, we can ask it to classify wines. We make a difference between the performance on the wines in the training set (on which the model is trained) and the wines in the test set. Obviously, the model performs better on data on which it has been trained than on data it has never seen. Imagine, if all the assignments on an exam would be the same as the assignments you used to study with. It would make for a rather easy exam.\n",
    "\n",
    "KNN performs rather well on the training set. The model is able to identify more than 70% of the top wines. On the test the accuracy is not much higher than our baseline of 0.867. The recall is also much lower, around 50%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9061545408664701\n",
      "Train recall: 0.7414578587699316\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \" + str(knn.score(X_train_knn, y_train_label)))\n",
    "print(\"Train recall: \" + str(recall_score(knn.predict(X_train_knn), y_train_label)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8681222359456552\n",
      "Test recall: 0.49576719576719575\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \" + str(knn.score(X_test_knn, y_test_label)))\n",
    "print(\"Test recall: \" + str(recall_score(knn.predict(X_test_knn), y_test_label)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenomenon in which a model score much higher on the training set than on the test set is called *overfitting*. When a model overfits, the model is only good in classifying or predicting on the data it has seen and not on the data it has never seen. \n",
    "\n",
    "A good analogy to understand overfitting are the [anti-tank dogs](https://en.wikipedia.org/wiki/Anti-tank_dog) trained by the Sovjets. Dogs were meant to be trained to leave explosive packages under German tanks, which would be detonated. The dogs were trained on Sovjet diesel tanks and not on German gasoline tanks. Unsuprisingly, when deployed, the dogs ran towards the familiar Sovjet tanks instead of the German tanks. This meant that the dogs had been trained too well on the Sovjet tanks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model we will take a look at is logistic regression, a cousin of linear regression. The main difference between the models is that linear regression can be used to predict a continious value, while logistic regression can be used to classify e.g. either 0 or 1. The curve of a logistic regression model fitted on only one feature looks like this:\n",
    "\n",
    "![LGurl](https://miro.medium.com/max/770/1*zfH9946AssCx4vzjaizWeg.png \"LG\")\n",
    "\n",
    "Source: https://miro.medium.com/max/770/1*zfH9946AssCx4vzjaizWeg.png\n",
    "\n",
    "Instead of one variable, we have 1000 variables. Just try to imagine how such a line would look like in a 1000 dimensional plane. Luckily, Python and the Sklearn LogisticRegression model will take care of this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train_reduced, y_train_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance on the training set is lower than the performance of KNN. However, the difference betweent the performance on the training set and test set is much lower. The logistic regression does not overfit and outperforms the KNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8932982707785481\n",
      "Train recall: 0.7241147467503362\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \" + str(clf.score(X_train_reduced, y_train_label)))\n",
    "print(\"Train recall: \" + str(recall_score(clf.predict(X_train_reduced), y_train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8917885174708156\n",
      "Test recall: 0.6918990703851262\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \" + str(clf.score(X_test_reduced, y_test_label)))\n",
    "print(\"Test recall: \" + str(recall_score(clf.predict(X_test_reduced), y_test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have arrived at the (in)famous branch of machine learning: neural networks. They have achieved unbelievable results on tasks that include object classification, natural language generating and machine translation. I would have no idea where to start to explain how these networks work; calling them complex would be an understatement. They consist of conventional linear or logistic models on steroids stacked on top of eachother. They are notorious for overfitting and ideally require much more data than we have in our example. If you are interested in learning about how such models work, I advise to start to watch the great videos of [Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk) and then progress with http://www.deeplearningbook.org/. \n",
    "\n",
    "Below, a relatively simple feed-forward network has been constructed by using the keras package. This package is ideal when starting to use neural networks in Python. Due to how neural networks, we have to change the encoding of the labels from 0 (mediocere wine) to [1, 0] and from 1 (top wine) to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "train_dummy_y = np_utils.to_categorical(y_train_label)\n",
    "test_dummy_y = np_utils.to_categorical(y_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialize a model. Next, we add layers to the model. The model below has one input layer with 64 nodes, one hidden layer with 32 nodes and one output layer with 2 nodes, corresponding to the number of wine classes we have. The compile method specifies how the model will be trained; for the scope of this article, I will not get in too much detail on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                64064     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 66,210\n",
      "Trainable params: 66,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation = \"relu\", input_shape = (1000, )))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(32, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can utilize some tricks to help our model to train and to reduce the training time. First, we specifiy the weights the model should attach to the errors of the classes. Since we have far less top wines in our data set, we weigh them more than the other wines. The weights are proportional to the proportion of classes in the training data. This helps to increase the recall on our unbalanced data set.\n",
    "\n",
    "Second, we use early stopping. The model will be trained in a given number of rounds i.e. epochs. With early stopping, we ask the model to check the accuracy of the model on the test data set. If the accuracy does not increase substantially in 5 rounds straight, the model stops training. This method can reduce overfitting and shortens the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {1:1/(np.sum(y_train_label)/ len(y_train_label)), 0:1}\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_acc', mode='auto', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we finally train our model. Additionaly to the training data, we specify the test data as validation data, set the amount of epochs to 50, point to the class weights and specify earlystopping. Below, you can see the performance of the model increasing over the epochs. Due to early stopping, our model is done after 24 epochs instead of 50 epochs, which cuts the training time in half.\n",
    "\n",
    "After the model is done training, we plot the accuracy on the training and test set for each epoch. Further, we print the recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75294 samples, validate on 25099 samples\n",
      "Epoch 1/50\n",
      "75294/75294 [==============================] - 9s 122us/step - loss: 0.8636 - acc: 0.7452 - val_loss: 0.4774 - val_acc: 0.7574\n",
      "Epoch 2/50\n",
      "75294/75294 [==============================] - 6s 74us/step - loss: 0.7394 - acc: 0.7848 - val_loss: 0.4280 - val_acc: 0.7905\n",
      "Epoch 3/50\n",
      "75294/75294 [==============================] - 6s 81us/step - loss: 0.6613 - acc: 0.8115 - val_loss: 0.4815 - val_acc: 0.7695\n",
      "Epoch 4/50\n",
      "75294/75294 [==============================] - 5s 70us/step - loss: 0.5767 - acc: 0.8424 - val_loss: 0.3508 - val_acc: 0.8416\n",
      "Epoch 5/50\n",
      "75294/75294 [==============================] - 5s 71us/step - loss: 0.5032 - acc: 0.8661 - val_loss: 0.3213 - val_acc: 0.8616\n",
      "Epoch 6/50\n",
      "75294/75294 [==============================] - 5s 71us/step - loss: 0.4384 - acc: 0.8859 - val_loss: 0.3444 - val_acc: 0.8562\n",
      "Epoch 7/50\n",
      "75294/75294 [==============================] - 6s 80us/step - loss: 0.3934 - acc: 0.9003 - val_loss: 0.3232 - val_acc: 0.8728\n",
      "Epoch 8/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.3622 - acc: 0.9071 - val_loss: 0.3030 - val_acc: 0.8847\n",
      "Epoch 9/50\n",
      "75294/75294 [==============================] - 7s 95us/step - loss: 0.3280 - acc: 0.9164 - val_loss: 0.3714 - val_acc: 0.8568\n",
      "Epoch 10/50\n",
      "75294/75294 [==============================] - 7s 93us/step - loss: 0.3111 - acc: 0.9200 - val_loss: 0.3010 - val_acc: 0.8895\n",
      "Epoch 11/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.2903 - acc: 0.9264 - val_loss: 0.2951 - val_acc: 0.8968\n",
      "Epoch 12/50\n",
      "75294/75294 [==============================] - 7s 93us/step - loss: 0.2782 - acc: 0.9302 - val_loss: 0.3000 - val_acc: 0.8945\n",
      "Epoch 13/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.2516 - acc: 0.9371 - val_loss: 0.3253 - val_acc: 0.8887\n",
      "Epoch 14/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.2512 - acc: 0.9362 - val_loss: 0.2949 - val_acc: 0.9015\n",
      "Epoch 15/50\n",
      "75294/75294 [==============================] - 7s 97us/step - loss: 0.2348 - acc: 0.9405 - val_loss: 0.2825 - val_acc: 0.9109\n",
      "Epoch 16/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.2225 - acc: 0.9436 - val_loss: 0.3167 - val_acc: 0.8989\n",
      "Epoch 17/50\n",
      "75294/75294 [==============================] - 7s 95us/step - loss: 0.2103 - acc: 0.9467 - val_loss: 0.3038 - val_acc: 0.9082\n",
      "Epoch 18/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.2041 - acc: 0.9485 - val_loss: 0.2991 - val_acc: 0.9156\n",
      "Epoch 19/50\n",
      "75294/75294 [==============================] - 7s 95us/step - loss: 0.1942 - acc: 0.9504 - val_loss: 0.2931 - val_acc: 0.9160\n",
      "Epoch 20/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.1922 - acc: 0.9521 - val_loss: 0.3170 - val_acc: 0.9075\n",
      "Epoch 21/50\n",
      "75294/75294 [==============================] - 7s 94us/step - loss: 0.1782 - acc: 0.9559 - val_loss: 0.3107 - val_acc: 0.9104\n",
      "Epoch 22/50\n",
      "75294/75294 [==============================] - 7s 97us/step - loss: 0.1778 - acc: 0.9558 - val_loss: 0.3244 - val_acc: 0.9095\n",
      "Epoch 23/50\n",
      "75294/75294 [==============================] - 7s 95us/step - loss: 0.1738 - acc: 0.9562 - val_loss: 0.3167 - val_acc: 0.9109\n",
      "Epoch 24/50\n",
      "75294/75294 [==============================] - 7s 95us/step - loss: 0.1675 - acc: 0.9581 - val_loss: 0.3404 - val_acc: 0.9096\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall train:  0.9997010165437512\n",
      "Recall test:  0.7802064359441409\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_reduced, train_dummy_y, validation_data=(X_test_reduced, test_dummy_y), epochs = 50, class_weight=class_weight, callbacks = [es])\n",
    "\n",
    "plt.plot(history.history['acc'], label = \"train\")\n",
    "plt.plot(history.history['val_acc'], label = \"test\")\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Recall train: \", recall_score(np.argmax(train_dummy_y, axis = 1),  np.argmax(model.predict(X_train_reduced), axis = 1)))\n",
    "print(\"Recall test: \", recall_score(np.argmax(test_dummy_y, axis = 1),  np.argmax(model.predict(X_test_reduced), axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see clearly in the plot, our model overfitted. The accuracy on the training set is well above 95%, while the accuracy on the test set does not surpass much above 90%. We see the same on the recall. In the training set, almost 100% of the top wines are classified correctly, while 78% of the top wines are classified correctly in the test set. Nevertheless, this model is the top performer so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have arrived at our last model: gradient boosting. To be honest, I never used this model before writing this article. I read online that this model is often being used in online data science challanges and often ends in the top, so I thought I can give it a try. I had the idea that in the end nothing can really top the accuracy and recall of a neural network; I could not have been more wrong. \n",
    "\n",
    "An extreme oversimplification of how this model works:\n",
    "* Fit a model to the data: F(x) = y\n",
    "* Fit a model to the residuals: h(x) = y - F_1(x)\n",
    "* Create a new model\n",
    "* Repeat\n",
    "\n",
    "In the end, you have an esemble of models that individually would not perform competitive on the data, but together can achieve impressive results.\n",
    "\n",
    "The gradient boosting implementation of [XGBoost](https://xgboost.readthedocs.io/en/latest/) has been used. The classifier has all the default hyperparameters, except max_depth is set from 3 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=8, min_child_weight=1, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
      "       subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(max_depth = 8)\n",
    "model.fit(X_train_reduced, y_train_label)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kees\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9840624750976174\n",
      "Train recall: 0.998307761732852\n",
      "Test accuracy: 0.9258536196661221\n",
      "Test recall: 0.9197422378441711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kees\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train_reduced)\n",
    "print(\"Train accuracy: \" + str(accuracy_score(predictions, y_train_label)))\n",
    "print(\"Train recall: \" + str(recall_score(predictions, y_train_label)))\n",
    "predictions = model.predict(X_test_reduced)\n",
    "print(\"Test accuracy: \" + str(accuracy_score(predictions, y_test_label)))\n",
    "print(\"Test recall: \" + str(recall_score(predictions, y_test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I first saw these results I was baffled. The recall on the test set smashes the results from the neural network. I never expected to be able to identify over 90% of all the top wines in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this article I showed how you can utilize a wide range of methods and models to make sense of text. I hope you take away from this article:\n",
    "* How to go about converting raw text to data on which we can train models\n",
    "* Which metrics you can use to evaluate models\n",
    "* The notion that there is no silver bullet in machine learning\n",
    "* And of course, the ridiculous performance of gradient boosting\n",
    "\n",
    "This article demonstated how one could go about a rather simple classification problem using embeddings and four different machine learning models. However, there are still a wide range of options to try out on this data set or a similair one:\n",
    "* Try to use a more recent and state of the art sentence embedding model such as BERT or XLNet.\n",
    "* Most models have been used with their default hyperparameters. See if you can increase the performance by applying cross validation.\n",
    "* Instead of classifying top wines, you can also try to predict the actual score of the wine, which would make this a regressions problem instead of a classification problem.\n",
    "\n",
    "You can access the notebook of this code online with the following link: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
